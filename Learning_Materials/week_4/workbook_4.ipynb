{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dae6289d-998e-42ed-8ade-d9a55526d67b",
   "metadata": {},
   "source": [
    "# Workbook 4: Local Search in categorical and continuous spaces\n",
    "## Introduction\n",
    "This workbook focusses on the final search algorithm that we have discussed but not asked you to implement so far: Local Search.  \n",
    "\n",
    "We will focus on perturbative approaches\n",
    "\n",
    "To develop your understanding you will:\n",
    "- Start with a simple binary problem that local search should be able to solve.\n",
    "- Look at a binary problem local search cannot solve without some changes\n",
    "- Adapt the **SingleMemberSearch** class to work with continuous decision variables,  \n",
    "   using  continuous version of the first binary problem. \n",
    "\n",
    "## Aims of this practical\n",
    "1. To give you the experience of  implementing, and evaluating the behaviour of local search in categorical problems.\n",
    "2. To give you experience of comparing the behaviour of different search algorithms.\n",
    "3. To give you experience of evaluating the efficiency of an algorithm for a problem ( in this case path-planning) by creating different instances of a problem (mazes) to *stress-test* different methods. \n",
    "\n",
    "# This is not an assessed workbook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd62e37-11a7-4d2c-b1be-2928935831e5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## reminder: Pseudocode for function SelectAndMoveFromOpenList in Local Search\n",
    "### This assumes the search process maintains track of *bestSoFar*\n",
    "<div style=\"background:#F0FFFF;font-size:18pt\">\n",
    "<p style=\"color:darkred;font-size:18pt;margin-bottom:0pt\"><em>SelectAndMoveFromOpenList</em></p>\n",
    "<dl style=\"font-size:18pt;margin-top:0pt\">\n",
    "    <dt>&nbsp;&nbsp;&nbsp;<b>IF</b> IsEmpty( open_list) <b>THEN</b> </dt>\n",
    "    <dd> RETURN None</dd>\n",
    "    <dt> &nbsp;&nbsp;&nbsp;<b>ELSE</b></dt>\n",
    "    <dd>bestChild &larr; <b>GetMemberWithHighestQuality</b>(openList)</dd>\n",
    "    <dd> <b>EMPTY</b>(openlist)&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"background:pink\">This prevents backtracking</span></dd>\n",
    "    <dd>  <b>IF</b> BetterThan(bestChild, bestSoFar) <b>THEN</b> <br>\n",
    "        &nbsp;&nbsp;&nbsp;&nbsp;bestSoFar &larr; bestChild <br>\n",
    "        &nbsp;&nbsp;&nbsp;&nbsp;RETURN bestChild </dd>\n",
    "    <dd> <b>ELSE</b> <br>&nbsp;&nbsp;&nbsp;&nbsp; RETURN None</dd>\n",
    "</dl>\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19af297-72bb-491a-996c-a0042b2d6f9b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\" style=\"color:black\">\n",
    "    <h2> Activity 1: implementing local search for a binary problem</h2>\n",
    "    <ol>\n",
    "        <li>Run the first cell to do some standard imports.</li>\n",
    "    <li>Then complete the second cell which contains an incomplete implementation of local search.</li>\n",
    "        <ul>\n",
    "            <li> We have provided an <code>__init__()</code> method with over-rides the default behaviour and creates a random starting point</li>\n",
    "            <li> <b> You need to complete</b> the method <code>select_and_move_from_openlist()</code>.</li>\n",
    "            <li> We have broken this down into <b>4</b> clearly marked small steps</li>\n",
    "            <li> The first step you need to complete uses similar code to BestFirstSearch()</li>\n",
    "            </ul>\n",
    "    <li> Test your implementation by running the third cell which uses your implementation to solve the <em>oneMax</em> problem. <br>\n",
    "        This is a simple binary maximisation problem where the quality is the number of the decision variables set to 1.</li>\n",
    "    </ol>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35906a4-1292-4bdd-9ef5-24be781348dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd49c91-ddef-4115-b6b9-1270fc90bf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU MUST RUN THIS CELL BUT DO NOT EDIT IT OR YOU WILL BREAK THE NOTEBOOK\n",
    "import copy\n",
    "import importlib\n",
    "import sys, os\n",
    "sys.path.append(os.path.join(os.path.dirname(sys.path[0]), 'common'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2e6951-f764-400b-a71b-439516510d60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from candidatesolution import CandidateSolution\n",
    "from singlemembersearch import SingleMemberSearch\n",
    "from problem import Problem\n",
    "from onemaxproblem import OneMaxBinary, OneMaxContinuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b3cea1-eb18-43ff-b1ac-5f5b8c46b2f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LocalSearch(SingleMemberSearch):\n",
    "    \"\"\"Implementation of local search.\"\"\"\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        \"\"\" return name\"\"\"\n",
    "        return \"local search\"\n",
    "    \n",
    "    def __init__( self,\n",
    "        problem: Problem,\n",
    "        constructive: bool = False,\n",
    "        max_attempts: int = 50,\n",
    "        minimise=True,\n",
    "        target_quality=1):\n",
    "        \"\"\" call super class \n",
    "        then change to random starting point\n",
    "        \"\"\"\n",
    "        super().__init__(problem, constructive=constructive,\n",
    "                       max_attempts=max_attempts,\n",
    "                       minimise=minimise,\n",
    "                       target_quality=target_quality)\n",
    "        # over-ride default\n",
    "        arrays_of_rands = np.random.choice(my_binary_onemax.value_set,size=num_vars)\n",
    "        start_point =  self.open_list[0]\n",
    "        start_point.variable_values= list(arrays_of_rands)\n",
    "        #measure quality \n",
    "        start_point.quality = self.problem.evaluate(start_point.variable_values)\n",
    "        if start_point.quality == self.target_quality:\n",
    "            self.trials = 1\n",
    "            self.result = start_point.variable_values\n",
    "            self.solved = True\n",
    "        \n",
    "        \n",
    "\n",
    "    def select_and_move_from_openlist(self) -> CandidateSolution:\n",
    "        \"\"\"Pops best thing from list, \n",
    "        clears rest of list, \n",
    "        then returns best thing\n",
    "        relies on the presence of self.best_so_far\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        next\n",
    "           working candidate (solution) taken from open list\n",
    "           **if it is an improvement**\n",
    "        None\n",
    "           IF list is empty OR next thing is worse than best so far\n",
    "        \"\"\"\n",
    "        next_soln = CandidateSolution()\n",
    "\n",
    "        # edge cases\n",
    "        if len(self.open_list) == 0:\n",
    "            self.runlog += \"LS:empty open list\\n\"\n",
    "            return None\n",
    "\n",
    "        # get best child: start looking for it in position 0\n",
    "        best_index = 0\n",
    "        quality = self.open_list[0].quality\n",
    "        best_so_far: int = quality\n",
    "        # ====>> insert your code below  to copy the best solution from the open list into next_soln\n",
    "        \n",
    "        # ====>> insert your code above  to copy the best solution from the open list into next_soln\n",
    "\n",
    "        self.runlog += (\n",
    "            f\"\\t best child quality {best_so_far},\"\n",
    "            f\"\\n\\t best so far {self.best_so_far}\\n\"\n",
    "        )\n",
    "        # clear the openlist\n",
    "        # =====>> insert your code below here to clear the openlist\n",
    "        \n",
    "        # <<===== insert your code above here to clear the openlist\n",
    "\n",
    "        # always accept first move\n",
    "        improvement_found: bool \n",
    "        if self.trials == 1:\n",
    "            improvement_found = True\n",
    "        # otherwise there must be an improvement\n",
    "        else:\n",
    "            pass\n",
    "            #value will depend on whether next_soln.quality improves on self.best_so_far\n",
    "            # ====>> insert your code below to set the value of variable improvement_found after first trial\n",
    "        \n",
    "            # ====>> insert your code above to set the value of variable improvement_found after first trial\n",
    "\n",
    "        \n",
    "\n",
    "        #return best offspring from open listor None if it doesn't improve on self.best_so_far\n",
    "        # =====> insert your code below to manage the return\n",
    "        \n",
    "        # =====> insert your code above manage the return\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544a8024-6964-4821-a605-494e24d122de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#define and create problem instance\n",
    "num_vars = 20\n",
    "\n",
    "my_binary_onemax = OneMaxBinary(N=num_vars)\n",
    "\n",
    "#create search\n",
    "mysearch = LocalSearch( my_binary_onemax,\n",
    "                        constructive = False,\n",
    "                        max_attempts= 500,\n",
    "                        minimise=False,\n",
    "                        target_quality=num_vars)\n",
    "\n",
    "starting_quality = mysearch.open_list[0].quality\n",
    "success = mysearch.run_search()\n",
    "if success:\n",
    "    print ( f'Run  found the goal ({num_vars})'\n",
    "            f'starting from point with quality {starting_quality}'\n",
    "            f' after examining {mysearch.trials} solutions.'\n",
    "          )\n",
    "else:\n",
    "    print(f'Run  failed to solve the problem in {mysearch.max_attempts} trials\\n'\n",
    "          f' runlog is:\\n {mysearch.runlog}'\n",
    "         )\n",
    "    completed_ok=False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ff9ec1-c088-4958-a1a9-a6bd7c1ffb6a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\" style=\"color:black\">\n",
    "    <h2> Activity 2: Evaluating your implementation of implementing local search</h2>\n",
    "    <p>Once your code works and the cell above runs and finds a solution, it is time to evaluate its performance.</p>\n",
    "    <p> Because it usually starts from a different random place every time, Local Search is a <b> stochastic</b> algorithm \n",
    "            ( the technical term for an algorithm that has a <b> random</b> element).<br>\n",
    "             This means that to analyse its behaviour we should run several times and report the <b>average</b> number of solutions it tries before it finds the goal.</p><p><b> Steps to do</b></p><ol>\n",
    "    <li>Run the cell above ten times (i.e. ten repetitions) with <em>num_vars= 10</em> and note the number of attempts needed to solve the problem.\n",
    "        <ul>\n",
    "        <li> You might like to record these in an excel spreadsheet or similar</li>\n",
    "        <li> You might also chose to edit the code to automatically run 10 repetitions and calculate the mean and standard deviation of the number of trials</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Then repeat, increasing the value of <em>num_vars</em> from 10 to 30 in steps of five </li>\n",
    "    <li> Plot your results as a curve of mean values (y-axis) vs num_vars (x-axis) with error bars showing the standard deviation.<br>\n",
    "        The cell below shows you first introduction to the graphics package <b> matplotlib</b> - just comment out the last few lines if you prefer to use something like excel</li>\n",
    "        </ol>\n",
    "    Can you explain what it is that makes this problem so easy?\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e3bddf-79e8-462e-9b0f-835b9fe8b280",
   "metadata": {},
   "source": [
    "<div>\n",
    "<div style=\"padding:10px;width:45%;color:black;background-color:yellow;float:left\">\n",
    "    <h3> How to examine results when the algorithm contains randomness</h3>\n",
    "    <p>Lots of AI algorithms- both for search/optimisation and machine learning - use some form of randomness.\n",
    "        This means that you might get a different result each time you run them on the same problem (or dataset).\n",
    "        So two understand or compare results (scientists typically call these <i>observations</i>) we need to look at</p>\n",
    "    <div>\n",
    "         <div style=\"float:right\">\n",
    "            <img src=\"https://curvebreakerstestprep.com/wp-content/uploads/2021/04/standard-deviation.png\" width=\"300\" height=\"300\">\n",
    "        </div>\n",
    "        <div \"padding:10px;width:25%;color:black;background-color:yellow;float:left\">\n",
    "        <ol> \n",
    "        <li>The average case behaviour.<br> Normally we use the <b>mean</b>, which is calculated as the sum of the observed values, divided by the number of observations.</li>\n",
    "        <li> The amount of difference between observations. <br>\n",
    "            Usually we use the <b> Standard Deviation</b>, a measure of how much, on average, results differ from the mean (ignoring the sign of the difference).</li>\n",
    "        </ol>\n",
    "        </div>\n",
    "    </div>\n",
    "    <p> To give a simple example, lets say you run a test in which 5 people score 10, and 5 people score 0.<br>\n",
    "        The mean= (5*10 +5*0)/10 = 5, but the  standard deviation= 5 as well - since everyone gets a score 5 different from the mean. <br> If we rerun the test but this time everyone gets 4 or 6. Now our mean is still 5 ( 5*4 +5*6 = 50 ), but the standard deviation will be 1. <br>So smaller values of standard deviation means the results are more similar to each other.</p>\n",
    "</div>\n",
    "<div style=\"padding:10px;width:45%;background-color:lightgreen;float:right\">\n",
    "<h3> HINTS on how to do this efficiently</h3>\n",
    "<ol>\n",
    "    <li> If you have three arrays for the problem size (x-axis),  number of attempts for each size (y-axis),  and standard deviations  for each size, then you can make a nice plot using the code snippets provided below </li>\n",
    "<li> You can automate finding the values for these arrays with two loops:<br>\n",
    "    The first loop is over problem sizes (10,15,20,25,30) inside which:<ul>\n",
    "    <li> make an array called <code>attempts</code> full of zeros of size REPETITIONS (e.g. 10)</li>\n",
    "    <li> then have an inside loop which goes  <code>for run in range( REPETITIONS)</code> times <ul>\n",
    "        <li> make a new instance of the problem, of the appropriate size</li>\n",
    "    <li> make a new search object <code>mysearch</code></li>\n",
    "    <li> call the <code>mysearch.runsearch()</code> method</li>\n",
    "    <li> store the number of solutions it looked at in <code>attempts[run]</code></li></ul>\n",
    "    <li> Now you can use numpy's built in functions <br> e.g.<code>np.mean(attempts)</code> and <code>np.std(attempts)</code> <br>\n",
    "    to calculate and store the mean and standard deviation of the number of attempts for this problem size</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b69ef3-8c20-42a5-8e48-a2fc4e090f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max attempts 10000\n",
    "MAX_ATTEMPTS =10000\n",
    "\n",
    "#number of repetitions\n",
    "REPEATS = 10\n",
    "\n",
    "sizes= [10,15,20,25,30]\n",
    "means = np.zeros(len(sizes))\n",
    "std_deviations=np.zeros(len(sizes))\n",
    "\n",
    "\n",
    "# ===>your code below here\n",
    "\n",
    "# copy-paste the code from the cell above and wrap it in a loop \n",
    "# that stores the number of solutions tested in each run \n",
    "\n",
    "# after that loop   report mean, and standard deviation of these\n",
    "\n",
    "# <====== your code above here\n",
    "\n",
    "# for making the plots\n",
    "from matplotlib import pyplot as plt\n",
    "#plot results    \n",
    "plt.errorbar(sizes,means, yerr=std_deviations)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e1ed83-167e-45ed-a935-83243d0aca06",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\" style=\"color:black\">\n",
    "    <h2> Activity 3: Adapting local search for a continuous problem</h2>\n",
    "    <h3> This is a stretch activity for the more confident coders.</h3>\n",
    "    <p>For continuous problems you will need to adapt your local search class.</p>\n",
    "    <p>This requires adapting more of the methods from the single member search class</p>\n",
    "    <p>I've suggested code that changes the <em>__init__</em> method \n",
    "            to initialise with appropriate continuous values,\n",
    "        and stores the number of samples to take from the neighbourhood each iteration, and whether to use gradient-based search or not.</p>\n",
    "    <p> <b>So the first thing you need to do</b> is over-ride the <em>select_and_move_from_openlist(self)</em> method\n",
    "        from your LocalSearch class so that it now accepts solutions that are as good \n",
    "        as <em>self.best_so_far</em> and not just improvements.</p>\n",
    "    <p> <b>The second thing you need to do </b> is to over-ride and change the <em>run_search()</em> method so that it:</p>\n",
    "        <ol> \n",
    "            <li>generates a number of neighbours defined by self.sample_size</li>\n",
    "            <li> for each neighbour creates a set of changes (one for each decision) then adds those then truncates to the valid range of values (using function provided()\n",
    "            <li> If  <em> self.use_gradients</em> is <em>False</em> it generates the list of changes at random <br>\n",
    "                If it is <em>True</em> it calls <em>self.problem.get_gradient()</em> then multiplies the result by <em>self.learning_rate</em> to get the changes</li>\n",
    "            <li> after looking at all of the neighbours, if they were all worse than what we had already, the open_list will be empty, so you  you need to put the <em>working_candidate</em> back on the open list instead of the closed list.</li> \n",
    "        </ol>\n",
    "\n",
    " <h3> This version of the problem has a quality function that is the difference to  the target so it needs to be minimised</h3>   \n",
    "    <p>It also provides a <em>get_gradient() method</em> so you can try both approaches described in the lecture</p>   \n",
    "\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280e72ed-36f5-4bde-a15a-f3c053b44c14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "   \n",
    "class LocalSearchContinuous(SingleMemberSearch):\n",
    "    \"\"\"Implementation of local search for continuous problems.\n",
    "      Assumes the search mode is perturbative.\n",
    "      Extends single member search by doing explicit sampling of neighbourhood\n",
    "      and if not stopping if no improvment is  found in an iteration\n",
    "      Parameters\n",
    "      ---------\n",
    "      sample_size(int): \n",
    "          number of neighbours to generate each iteration\n",
    "          default 10\n",
    "      use_gradient(bool): \n",
    "          whether to use the gradient instead of random changes\n",
    "          if the problem supports it.\n",
    "          If set, assume sample_size is 1\n",
    "          default False\n",
    "      learning_rate(float)\n",
    "          multiplier for gradient if used\n",
    "          default 0.5\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return \"local search continuous\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        problem: Problem,\n",
    "        constructive: bool = False,\n",
    "        max_attempts: int = 50,\n",
    "        minimise:bool=True,\n",
    "        target_quality:float=1,\n",
    "        sample_size:int = 10,\n",
    "        use_gradient:bool=False,\n",
    "        learning_rate=0.5\n",
    "    ):   \n",
    "        super().__init__(problem, constructive=constructive,\n",
    "                       max_attempts=max_attempts,\n",
    "                       minimise=minimise,\n",
    "                       target_quality=target_quality)\n",
    "        print(f'self.target_quality is {self.target_quality}') \n",
    "        #reinitialise to random continuous values in right range\n",
    "        self.num_vars  = len(self.open_list[0].variable_values)        \n",
    "        for decision in range(self.num_vars):\n",
    "            self.open_list[0].variable_values[decision]= self.rand_in_range()\n",
    "        #re-evaluate\n",
    "        quality = self.problem.evaluate(self.open_list[0].variable_values)\n",
    "        self.open_list[0].quality=quality    \n",
    "\n",
    "        #store the number of neighbours to examine each iteration \n",
    "        self.sample_size = sample_size\n",
    "\n",
    "        #does the problem support calculation of gradients\n",
    "        self.use_gradient= use_gradient\n",
    "        self.learning_rate = learning_rate\n",
    "        if self.use_gradient:\n",
    "            try:\n",
    "                _=self.problem.get_gradient()\n",
    "                self.sample_size = 1\n",
    "            except:\n",
    "                self.use_gradient=False\n",
    "\n",
    "    def rand_in_range(self)->float:\n",
    "        \"\"\" generates a random number in the range\n",
    "        specified by the problem\n",
    "        \"\"\"\n",
    "        lowest_val = self.problem.value_set[0]\n",
    "        val_range = self.problem.value_set[1] - self.problem.value_set[0]\n",
    "        return np.random.random()*val_range +lowest_val\n",
    "    \n",
    "    def get_rand_normals_in_range(self)->list:\n",
    "        \"\"\" \n",
    "        generates random number form  normal distribtion\n",
    "        mean= midpoint of valid range for problem\n",
    "        sdev = 10% of valid range. for problem\n",
    "        \"\"\"\n",
    "        changes=[]\n",
    "        valrange = self.problem.value_set[1]-self.problem.value_set[0]\n",
    "        valmean =  (self.problem.value_set[1]+ self.problem.value_set[0])/2\n",
    "        for pos in range(self.num_vars):\n",
    "            randval= np.random.normal() *0.1*valrange + valmean\n",
    "            changes.append(randval)\n",
    "        return changes\n",
    "        \n",
    "    \n",
    "    \n",
    "    def truncate_to_range(self, val:float)->float:\n",
    "        \"\"\" truncates a val ot the valid range\n",
    "        defined by a problem\"\"\"\n",
    "        if val>self.problem.value_set[1]:\n",
    "            val = self.problem.value_set[1]\n",
    "        if val < self.problem.value_set[0]:\n",
    "            val = self.problem.value_set[0]\n",
    "        return val\n",
    "    \n",
    "    \n",
    "    def select_and_move_from_openlist(self) -> CandidateSolution:\n",
    "        \"\"\"Pops best thing from list, clears rest of list, then returns best thing\n",
    "        relies on the presence of self.best_so_far\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        next\n",
    "           working candidate (solution) taken from open list\n",
    "           if it is an improvem ent\n",
    "        None\n",
    "           IF list is empty OR next thing is worse than best so far\n",
    "        \"\"\"\n",
    "        next_soln = CandidateSolution()\n",
    "\n",
    "        # edge cases\n",
    "        if len(self.open_list) == 0:\n",
    "            self.runlog += \"LS:empty open list\\n\"\n",
    "            return None\n",
    "\n",
    "        # get best child\n",
    "        best_index = 0\n",
    "        quality = self.open_list[0].quality\n",
    "        best_so_far: int = quality\n",
    "        ## your code to put the right value from the open list into next_soln\n",
    "        \n",
    "        self.runlog += (\n",
    "            f\"\\t best child quality {best_so_far},\\n\\t best so far {self.best_so_far}\\n\"\n",
    "        )\n",
    "        # clear the openlist\n",
    "        ## Your code here\n",
    "        # always accept first move\n",
    "        if self.trials == 1:\n",
    "            better: bool = True\n",
    "        # otherwise must be an improvement or at least as good (to keep search going)\n",
    "        #i.e best_so_far must be at least as good as self.best_so_far\n",
    "        \n",
    "        # your code to return best from open list \n",
    "        #or None if it doesn't improve on self.best_so_far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eab913-601a-4048-820a-2acc354a01b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#search using option 1 from the lectures- adding gaussian noise\n",
    "num_vars = 10\n",
    "continuous_onemax = OneMaxContinuous(N=num_vars)\n",
    "mysearch2 = LocalSearchContinuous( continuous_onemax,\n",
    "                        constructive = False,\n",
    "                        max_attempts= 500,\n",
    "                        minimise=True,\n",
    "                        target_quality=0.0)\n",
    "    \n",
    "\n",
    "success = mysearch2.run_search()\n",
    "if success:\n",
    "    print ( 'Local Search solved the problem '\n",
    "           f' after {mysearch2.trials} attempts.\\n'\n",
    "           f'solution {mysearch2.result}\\n'\n",
    "           f' quality {mysearch2.problem.evaluate(mysearch2.result)[0]}'\n",
    "          )\n",
    "else:\n",
    "    print(f'failed to solve the problem in {mysearch2.max_attempts} trials\\n'\n",
    "          f' runlog is:\\n {mysearch2.runlog}'\n",
    "         )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72077101-54e9-4089-97b5-4d1e4dc67e93",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Now search using the gradient information\n",
    "\n",
    "mysearch3 = LocalSearchContinuous( continuous_onemax,\n",
    "                        constructive = False,\n",
    "                        max_attempts= 500,\n",
    "                        minimise=True,\n",
    "                        target_quality=0.0,\n",
    "                        use_gradient=True,\n",
    "                        learning_rate=0.5)    \n",
    "\n",
    "success = mysearch3.run_search()\n",
    "if success:\n",
    "    print ( 'Local Search solved the problem '\n",
    "           f' after {mysearch3.trials} attempts.\\n'\n",
    "           f'solution {mysearch3.result}\\n'\n",
    "           f' quality {mysearch3.problem.evaluate(mysearch2.result)[0]}'\n",
    "          )\n",
    "else:\n",
    "    print(f'failed to solve the problem in {mysearch3.max_attempts} trials\\n'\n",
    "          f' runlog is:\\n {mysearch3.runlog}'\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa229165-f33a-4be0-8c96-393e244ad855",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d40939-9924-46ee-b73c-8bbdd937e1f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3529b415-8528-4c76-abf9-b833471d33e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aienv",
   "language": "python",
   "name": "aienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
